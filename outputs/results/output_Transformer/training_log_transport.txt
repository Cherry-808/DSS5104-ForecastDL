
=================================================
Transformer Model Training Log (Google Colab)
=================================================
Date and Time: 2025-04-23 15:33:52 (UTC)

--- Data Configuration ---
Google Drive Base Path: /content/drive/MyDrive/Transformer_Project/
Data File: Baltimore_Lagged_Dataset.csv
Date/Index Column: Month
Target Column: Total TEUs
Feature Columns Used: ['Total TEUs', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_6', 'Lag_12']
Sequence Length: 15
Test Set Size: 0.2

--- Model Hyperparameters ---
Head Size: 128
Number of Heads: 4
Feed-Forward Dim: 128
Transformer Blocks: 4
MLP Units: [64]
Dropout: 0.1
MLP Dropout: 0.1

--- Training Details ---
Epochs Run: 27 (Max Epochs Configured: 50)
Batch Size: 64
Learning Rate: 0.0001
Best Model Saved To: /content/drive/MyDrive/Transformer_Project/best_transformer_model_transport.keras
Training Time: 54.97 seconds

--- Resource Usage ---
Memory Usage Before Training: 1377.90 MB
Memory Usage After Training: 1499.03 MB
Approx. Memory Increase During Training: 121.13 MB

--- Evaluation Metrics (Test Set) ---
RMSE: 32682.662323
MSE: 1068156416.515881
MAE: 31289.450918
MAPE (%): 88.85
R2 Score: -1.796374
Adjusted R2 Score: -2.112945

--- Output Files ---
Loss Curve Plot: /content/drive/MyDrive/Transformer_Project/loss_curve_transport.png
Prediction Plot: /content/drive/MyDrive/Transformer_Project/prediction_vs_actual_transport.png
Log File: /content/drive/MyDrive/Transformer_Project/training_log_transport.txt
=================================================
